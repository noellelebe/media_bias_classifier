# -*- coding: utf-8 -*-
"""hackingCommScience_MediaBias.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G0w43QhPHOoXmZbXWFyIFEg-34J9rbJ1

Code from https://thinkinfi.com/gensim-doc2vec-python-implementation/
"""

# from google.colab import drive
# drive.mount('/content/drive')

import gensim
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
print("gensim done")
import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize
print("nltk done")

import pandas as pd
import numpy as np
print("import done")

pprs = pd.read_csv("/Users/janabernhard/Documents/PhD/Unterricht/SS22_HackatonICA/germanyPPRs.csv", encoding = "UTF-8", encoding_errors="replace")
print("data read in")
pprs = pprs[["date", "text", "label"]]

# Tokenization of each document
pprs = pprs.dropna()
pprs = pprs.reset_index()

doc = pprs.text

tokenized_doc = []
for d in doc:
    tokenized_doc.append(word_tokenize(d.lower()))
print("tokenized")
# Convert tokenized document into gensim formated tagged data
tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]
print("start training")
## Train doc2vec model
model = Doc2Vec(tagged_data, vector_size=300, window=5, min_count=10, workers=4, epochs = 100)

# Save trained doc2vec model
model.save("/Users/janabernhard/Documents/PhD/Unterricht/SS22_HackatonICA/media_bias_classifier/bias/test_doc2vec.model")